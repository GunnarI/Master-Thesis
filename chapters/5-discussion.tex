\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter{Discussion}
\label{sec:discussion}
This chapter, as the previous, will be divided into two sections. 
The first section discusses the pre-training results and the second discusses the performance results of the trained model.
This includes a further discussion about why the model might generalize well for some cases but badly for others.

\section{Pre-training results}
\label{sec:discussion_pre-training-results}
The \ac{EMG} patterns from most of the muscles and the \acp{KJM} were shown to highly correlate linearly between subjects.
This might indicate that a mapping function that generalizes across subjects could be formulated.
However, as the relationship between the \ac{EMG} and \ac{KJM} is non-linear, it is difficult to see if the mapping from \ac{EMG} to \ac{KJM} is correlated between subjects.
Also, it should be emphasized that the subjects were all young, healthy adults.
Many have researched difference in \ac{EMG} signal between various target groups and varying conditions \cite{Courtine2003,Rezgui2013,Sacco2010, Zwaan2012}.
From these researches it can be concluded that \ac{EMG} signal can vary in amplitude, lag, and/or pattern depending on pathology and conditions.

The \ac{EMG} from gluteus maximus was observed to vary between subjects much more than the \ac{EMG} from other muscles.
There could be a number of reasons for this discrepancy, for example, differing location of the sensor.
It was more difficult to determine the correct sensor location for the gluteus maximus than for the other muscles.
It should also be mentioned that it was the only sensor that was located underneath the user's clothes (shorts), which may interfere with the signal.
Reasons could include increased perspiration. 
Sweat has been shown to dampen the signal \cite{Abdoli-Eramaki2012}.

The filtering of the \ac{sEMG} signal was enough to extract a pattern of muscle activation.
However, with a small moving average window of $50ms$, the filtered signal was not very smooth.
Future research could compare smoother signal's affect to the learning of the \ac{ANN}.
Additionally, by including the whitening step mentioned in section \ref{sec:data-processing}, the muscle activity could be captured more selectively \cite{Clancy2016}.
Further research could investigate if including the whitening step would improve the learning of the \ac{ANN}.
It should be emphasized that both of these method decisions were in favor of simpler solution for real-time application.
The moving average window was kept small to minimize delay of the \ac{EMG} signal and the whitening step was omitted to simplify the calibration process.
The whitening process requires calibration where the magnitude and phase of the whitening filter need to be determined \cite{Clancy2016}.

The normalization resulted in most of the normalized \ac{EMG} signal, including the peaks, being below $0.5$.
However, it might improve the pattern recognition if the peaks were generally closer to one and there would be more difference between active and non-active muscle.
For the normalization, the single highest peak of \ac{EMG} from each muscle, for the whole dataset, of each session, was used.
This peak may be caused by an erroneous spike.
An alternative could be to use an average of a number of the highest peaks.
Also, in real-time application, the user would not be expected to make around $300$ right-foot steps only for the calibration of the device.
Thus, selecting a random subset of only a few gait cycles for normalization would be a more fitting method.

\section{Post-training results}
\label{sec:discussion_post-training-results}
When looking at the results from section \ref{sec:post-training-results}, it is clear that the same model does not perform as well for every case.
The \ac{MLP} model generally performed much worse than the \ac{LSTM} model and did not manage to generalize well.
The \ac{MSE} of the training set always converged at a much higher value for the \ac{MLP} model than the \ac{LSTM} model.
Regardless, with respect to the error on the test set, the model is observed to be overfitting.
This indicates that an \ac{MLP}, or at least this particular \ac{MLP}, cannot be used to generalize between sessions.
The \ac{MLP} is only looking at \ac{EMG} data at one timestep, and trying to map it to a \ac{KJM} at the same timestep.
Arguably, this does not capture the task specific pattern of the \ac{EMG} as well as the \ac{LSTM} model.
However, a different design of the \ac{MLP} might improve its performance. 
It is impossible to state that no form of \ac{MLP} could outperform the \ac{LSTM}.

The design of the model had some iterations. 
One notable design criteria, that changed throughout the process, is the number of timesteps included in the \ac{LSTM} model.
Looking at 20 past samples of \ac{EMG} results in a rather deep network, when considering running it on an embedded system.
At first, fewer timesteps were used.
Those models performed adequately in cases where the testing set was a part of the same session's dataset as the training set.
However, they completely failed to generalize between subjects.
It was not until using 20 timesteps that the model was able to generalize to some extent.

Before discussing the results from each case, it should be noted that the distribution of gait cycles used is not equal between subjects, as seen in table \ref{tab:data-subject-distribution}. 
In fact, gait cycles measured from subject 6 constitute over half of all the gait cycles used.
\input{tables/data-subject-distribution.tex}

\subsection{Case 1 and 2}
\label{sec:discussion-case1and2}
Case 1 looks at the ability of the model to generalize across sessions, as conditions of subjects and equipment are not exactly the same between days. 
The results indicated that the model can generalize well between sessions.
However, this test should be conducted on more subjects, with added separate sessions, to reach a reliable conclusion.

The testing error was increased in case 2 where more subjects were added to the training set, compared to case 1.
Since the training and validation error is lower, this indicates that the difference between sessions of the same subject is less than the difference between subjects.
The increase in testing error is however, not large, and the model still performs reasonably well.
Further research could add more sessions from the same subject to the testing set, to show if there is increased flexibility to higher variation between sessions.
More specifically, to test if the overall testing error of several sessions would decrease when using case 2 rather than case 1.

\subsection{Case 3 and 4}
\label{sec:discussion-case3and4}
The results from case 3 indicated that the model does not generalize well across subjects.
However, as seen in case 4, it depends on which subjects are being trained on and which are being tested on.

It is difficult to say why the model performs better in case 4 than case 3.
One explanation could be the discrepancy in the \ac{EMG} signal of the gluteus maximus, discussed in chapter \ref{sec:results}.
Figure \ref{fig:emg-average} shows that the \ac{EMG} signal from gluteus maximus of subject 2 varies quite a bit from subjects 1 and 6.
In that way, the pattern of this \ac{EMG} signal is completely unknown to the model in case 3.
Furthermore, since the overall amplitude of the signal is much lower in the training set, the model may be too sensitive to the high values from the test set.

Further research could include more subjects with more variability to test if the prediction error can be decreased to a reasonable degree for every subject unseen to the model.

\subsection{Case 5}
\label{sec:discussion-case5}
The results from case 5 indicate that using more subjects with more variance in the training does not greatly influence the model's performance.
With increased variance in the training set, the model can be expected to perform better on unseen data.

\section{Real-time compatability}
\label{sec:discussion_real-time}
When used in an exoskeleton, the assistance (or resistance) of the exoskeleton may affect the \ac{EMG} signal \cite{Androwis2018}.
Since the model is based on the 20 past \ac{EMG} signals, this may create a bad feed-back loop where a faulty prediction affects \ac{EMG} measurements which in turn affects next prediction.

\end{document}