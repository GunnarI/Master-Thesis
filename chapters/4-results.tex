\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter{Results}
\label{sec:results}
The results can be split into two parts: (1) \textit{pre-training} which includes the experimental data after filtering and the pre-processing before the training; and (2) \textit{post-training} which includes the output from the trained \ac{NN} model, including training and performance evaluation.

\section{Pre-training results}
\label{sec:results_pre-training-results}
Before training the \ac{NN} it is useful to examine the data.
Figure \ref{fig:kjm-average} shows a representation of the \ac{KJM} from all the gait cycles for subjects 1, 2 and 6.
Same plots can be found for subject 3 and 5 in appendix \ref{sec:A-data-representation-4-subjects35}. 
Figure \ref{fig:emg-average} shows the corresponding \ac{EMG} activity of each muscle, grouped by the muscle's main function as per table \ref{tab:muscle-names}.
\begin{figure}[ht!]
     \centering
     \begin{subfigure}[b]{0.328\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/moment_avg/subject01_all_set1_moment_avg_w_minmax.png}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.328\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/moment_avg/subject02_all_set1_moment_avg_w_minmax.png}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.328\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/moment_avg/subject06_all_set1_moment_avg_w_minmax.png}
     \end{subfigure}
    \caption{Normalized \ac{KJM} for subjects 1, 2, and 6, from left to right. The x-axis is the percentage of a single gait cycle. The solid blue line is the average from all the gait cycles and the shaded area around it is the standard deviation.}
    \label{fig:kjm-average}
\end{figure}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]{img/results/emg_avg/all_subject_grid_emg_avg.png}
    \caption{Filtered and normalized \ac{EMG} from subjects 1, 2, and 6. The x-axis is the percentage of a single gait cycle. The solid blue lines represent the average from all the gait cycles for each muscle and the shaded area with corresponding color is the standard deviation.}
    \label{fig:emg-average}
\end{figure}
The figures show similar patterns between the subjects, for \acp{KJM} and \ac{EMG} signals over the gait cycles.
However the average normalized \ac{KJM} amplitude for subject 1 is much lower than for subjects 2 and 6.
As indicated by the ``fastest'' and ``slowest'' cycles, it is because subject 1 generally walked slower, in most trials, compared to their maximum speed.

% Considering similar patterns across subjects, an \ac{NN} might be able to generalize between subjects, at least up to some degree.
The linear correlation between the average for each subject, considering each of the muscles and the \ac{KJM}, is plotted in figures \ref{fig:A-kjm-and-glutmax-correlation}--\ref{fig:A-gasmed-and-gaslat-correlation}.
Table \ref{tab:correlation-sumup} outlines the results from these plots.
\input{tables/correlations-sumup.tex}
This table indicates that the patterns are generally correlated between subjects, except for the pattern of gluteus maximus.
This is also noticeable in figure \ref{fig:emg-average} where the \ac{EMG} pattern for gluteus maximus varies between subjects.

Another notable observation is the amplitude of the normalized \ac{EMG}.
It indicates that most of the values, including the peaks, have below $0.5$ amplitude.

\section{Post-training results}
\label{sec:post-training-results}
The following figures and tables show the training and performance results of the model for each case.
The performance is presented in the tables with the \ac{MSE} and \ac{MAE}.
Although \ac{MSE} was used for objective function during training, the \ac{MAE} gives a clearer picture of the size of the error as compared to the desired output.

\subsection{Case 1}
\label{sec:results-case1}
Case 1 is where the model was trained on one session of subject 6 and tested on another session of that same subject.
Subject 6 was the only subject with large enough datasets from separate sessions to reliably train and test the model in this case.
The model was trained on the bigger dataset, i.e. session 1.

Table \ref{tab:case1-test-eval} shows the error from running the model on the test set.
This error can be compared to the error trend of the validation and training set from figure \ref{fig:case1-training-performance}.
The result shows little overfitting, with the \ac{MSE} of the validation and testing set not being much higher than for the training set.
Figure \ref{fig:case1-prediction-performance} shows that on average, the model's \ac{KJM} predictions are close to the \ac{ID} outputs.
\input{tables/Case1_models_test-eval.tex}
\begin{figure}[!htb]
    % \captionsetup[subfigure]{aboveskip=-1pt}
     \centering
     \begin{subfigure}[b]{0.475\textwidth}
    %  \begin{minipage}{0.475\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/training_history/Case1_LSTMvsMLP_training.png}
         \subcaption{The training and validation set's \ac{MSE} per epoch during training.}
         \label{fig:case1-training-performance}
     \end{subfigure}
    %  \end{minipage}%
     \hfill
     \begin{subfigure}[b]{0.515\textwidth}
    %  \begin{minipage}{0.515\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/test_prediction_evaluation/Case1_LSTM_test_prediction.png}
         \subcaption{Test set's average \ac{KJM}; LSTM model prediction vs. actual (CGM2 output).}
         \label{fig:case1-prediction-performance}
     \end{subfigure}
    %  \end{minipage}
    \caption{Case 1 model performance}
    \label{fig:case1-performance-plots}
\end{figure}

\subsection{Case 2}
\label{sec:results-case2}
In case 2, both sessions from subjects 1 and 2 were added to the training set.
This shows how increasing variance in the training set affects the results from case 1.

Figure \ref{fig:case2-training-performance} shows that the training error and validation error was significantly decreased and the discrepancy between them was low, indicating decreased risk of overfitting.
However, the error of the test set increased when compared to case 1, as seen from tables \ref{tab:case1-test-eval} and \ref{tab:case2-test-eval}.
\begin{figure}[!htb]
    % \captionsetup[subfigure]{aboveskip=-12pt}
     \centering
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/training_history/Case2_LSTMvsMLP_training.png}
         \caption{The training and validation set's \ac{MSE} per epoch during training.}
         \label{fig:case2-training-performance}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.515\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/test_prediction_evaluation/Case2_LSTM_test_prediction.png}
         \caption{Test set's average \ac{KJM}; LSTM model prediction vs. actual (CGM2 output).}
         \label{fig:case2-prediction-performance}
     \end{subfigure}
    \caption{Case 2 model performance}
    \label{fig:case2-performance-plots}
\end{figure}
\input{tables/Case2_models_test-eval.tex}

\subsection{Case 3}
\label{sec:results-case3}
In case 3, the model was trained on subjects 1 and 6, and tested on subject 2.
When comparing the \ac{MSE} from figure \ref{fig:case3-training-performance} and table \ref{tab:case3-test-eval}, a high level of overfitting is observed.
The training set's error is much lower than for the validation and testing sets.
Incidentally, as seen on figure \ref{fig:case3-prediction-performance}, the model fails to predict the \acp{KJM} accurately, on average.
\begin{figure}[!htb]
    % \captionsetup[subfigure]{aboveskip=-12pt}
     \centering
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/training_history/Case3_LSTMvsMLP_training.png}
         \caption{The training and validation set's \ac{MSE} per epoch during training.}
         \label{fig:case3-training-performance}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.515\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/test_prediction_evaluation/Case3_LSTM_test_prediction.png}
         \caption{Test set's average \ac{KJM}; LSTM model prediction vs. actual (CGM2 output).}
         \label{fig:case3-prediction-performance}
     \end{subfigure}
    \caption{Case 3 model performance}
    \label{fig:case3-performance-plots}
\end{figure}
\input{tables/Case3_models_test-eval.tex}

\subsection{Case 4}
\label{sec:results-case4}
In case 4, the model was trained on subjects 2 and 6, and tested on subject 1.
Comparing tables \ref{tab:case3-test-eval} and \ref{tab:case4-test-eval} and figures \ref{fig:case3-training-performance} and \ref{fig:case4-training-performance} it is observed that the training and validation error for case 4 is much higher than for case 3, but the testing error is much lower.
Interestingly, the testing error in case 4 is even lower than the validation error.
The validation set contains unseen cycles from subject 2 which may induce similar results as in case 3.
\begin{figure}[!htb]
    % \captionsetup[subfigure]{aboveskip=-12pt}
     \centering
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/training_history/Case4_LSTMvsMLP_training.png}
         \caption{The training and validation set's \ac{MSE} per epoch during training.}
         \label{fig:case4-training-performance}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.515\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/test_prediction_evaluation/Case4_LSTM_test_prediction.png}
         \caption{Test set's average \ac{KJM}; LSTM model prediction vs. actual (CGM2 output).}
         \label{fig:case4-prediction-performance}
     \end{subfigure}
    \caption{Case 4 model performance}
    \label{fig:case4-performance-plots}
\end{figure}
\input{tables/Case4_models_test-eval.tex}

\subsection{Case 5}
\label{sec:results-case5}
In case 5, the model was trained and tested on all the subjects. 
The testing set was selected as random 20\% of the data, not presented to the model during training.
Comparing table \ref{tab:case5-test-eval} and figure \ref{fig:case5-training-performance}, there is little overfitting and the error for the validation and testing set is about the same.
Furthermore, the training and validation error are observed to converge at a relatively low value when compared to the other cases, even with the increased variance in these sets.
\newpage
\begin{figure}
    % \captionsetup[subfigure]{aboveskip=-12pt}
     \centering
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/training_history/Case5_LSTMvsMLP_training.png}
         \caption{The training and validation set's \ac{MSE} per epoch during training.}
         \label{fig:case5-training-performance}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.515\textwidth}
         \centering
         \includegraphics[width=\textwidth]{img/results/test_prediction_evaluation/Case5_LSTM_test_prediction.png}
         \caption{Test set's average \ac{KJM}; LSTM model prediction vs. actual (CGM2 output).}
         \label{fig:case5-prediction-performance}
     \end{subfigure}
    \caption{Case 5 model performance}
    \label{fig:case5-performance-plots}
\end{figure}
\input{tables/Case5_models_test-eval.tex}

\end{document}
