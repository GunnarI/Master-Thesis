\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter{State of the Art}
The concept of \textit{exoskeletons} as it will be used in this thesis refers to \textit{robotic exoskeletons} or \textit{powered exoskeletons}. 
They can be defined as mobile, computer controlled, electromechanical structures which can be worn by a human to provide power amplification, support and/or assistance in human motion \cite{Anam2012, Gorgey2018}. 
A typical powered exoskeleton would have a motor or some sort of actuator to produce torque at the joints (e.g. knee joint) to enable or assist the user.

The amount of torque produced for any given motion depends on the control system of the exoskeleton.
Many different methods have been researched and implemented towards the goal of making a good control system that provides exactly the assist that the user wants and/or needs.
The key to that goal is to estimate or predict the joint torque associated with a certain motion performed by the user.

This chapter discusses the state of the art of exoskeleton control systems and joint torque estimation.
That includes kinetic methods for joint torque estimation and the relationship of muscle activity and \ac{EMG} signals to joint torque.
Note that the overall focus is on lower extremities.
First, the discussion is aimed towards methods and models that are used today for kinetics of human motion analysis in general research and clinical applications.
This includes discussion about data acquisition, especially \ac{EMG} data, and its relation to the body dynamics, i.e. muscle forces.
Second, the discussion is narrowed towards the methods and models that can be used as control systems in an exoskeleton.
The flexibility for computation and data acquisition is lower in an exoskeleton where things happen in real-time and thus the number of methods that could be used more limited.
Third, the discussion is focused toward the state of the art of one particular method which consists of joint torque prediction using \ac{ANN} with \ac{EMG} data acquisition. 
This also includes discussion about the research of different \acp{ANN} used with \ac{EMG} data.

\section{Kinetics of Human Motion: methods, models, and data acquisition}
\label{sec:A-MSModels}
Kinetics of human motion is the study of the forces that cause human motion. 
This includes muscle forces as well as external forces, such as \acp{GRF}.
It is challenging to measure \textit{in vivo} muscle forces directly.
It requires at least a minimally invasive method or an open surgery, so that a force transducer can be placed on a tendon attached to the muscle \cite{Erdemir2007}. 
Thus, in general clinical application as well as in exoskeletons, measuring muscle forces directly is hardly an option.
However, it is possible with non-invasive methods to measure reaction forces like \ac{GRF}, human motion, and \ac{EMG}.
Several methods have then been developed to estimate joint torques and muscle forces using this data \cite{Erdemir2007}.

\subsection{Joint Moments from Inverse Dynamics}
\label{sec:A-Inverse-Dynamics}
\textit{\Acf{ID}} is, as defined by the Dictionary of Sport and Exercise Science and Medicine \cite{inversedynamics}, ``the calculation of forces and moments by using kinematics and data for mass and moment of inertia, effectively using Newton's second law of motion ($f = ma$) in reverse.''
In relation to the human body this means the use of kinetics and kinematics, e.g. motion capture, scaled model, and force plate data from a motion lab, to calculate joint torque estimations.
As the method works with the equation of motion, it relies on correct scaling of each body segment, and joints angles and positions relative to the reaction forces \cite{Erdemir2007, Buchanan2004}.

Using a motion lab one can collect the positions and motions of body segments using reflective markers that are sensed by specially designed motion cameras.
Sections \ref{sec:A-Vicon-and-PiG} and \ref{sec:A-pyCGM2} go into further detail about the definition of different body segments using specific markersets.
This includes scaling a skeleton model to the subject and defining joint centers relative to the markers.
Once the skeleton model has been scaled, it can be fitted to the motion capture by using \ac{IK}.
For the \ac{IK} problem, the objective function is the weighted squared error of the subject's measured markers and joint angles to the model's markers and angles, respectively.
The \ac{IK} problem then involves minimizing the objective function \cite{Delp2007}:
\begin{align}
\label{eq:ik-obj-func}
    \min(obj) = \min\biggl\{ &\sum_{i=1}^{\text{markers}}w_i \left(\Vec{x_i}^{sub}-\Vec{x_i}^{mod}\right)^2 \nonumber\\ 
    &+ \sum_{j=1}^{\text{joint angles}}w_j \left( \theta_j^{sub}-\theta_j^{mod}\right)^2 \biggr\}
\end{align}
where $\Vec{x_i}^{sub}$ and $\Vec{x_i}^{mod}$ are the global ($xyz$) coordinates of the $i$-th marker for the subject and model, respectively; 
and $\theta_j^{sub}$ and $\theta_j^{mod}$ the angles of the $j$-th joint.
The weights can be used to set the relative importance of specific joints to be fitted accurately.

After applying \ac{IK}, the model and its kinematics, have been fitted in the global coordinate system, relative to the \ac{GRF} from the force plates.
Finally, \ac{ID} can be applied using those kinematics and \acp{GRF} together with the anthropometric data of the segments.
Figure \ref{fig:ID-forces-and-segments} shows the translation of the \ac{GRF} to the segments' center of mass and joint centers \cite{cgm-ID, Dumas2004}.
\begin{figure}[!htb]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{img/ID_CGM2_labeled.png}
        \caption{Adapted from \cite{cgm-ID}}
        \label{fig:cgm-ID-force-prop}
    \end{subfigure}
    ~
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{img/Conventional_ID_labeled.png}
        \caption{Adapted from \cite{Dumas2004}}
        \label{fig:ID-thigh-force-def}
    \end{subfigure}
    \caption{Force propagation from the \ac{GRF} through the leg segments and how the forces and moments translate at the segment's center of mass (CoM) and joint centers (JC). Figure (a) demonstrates how the \ac{GRF} translates to moments in the joint centers. Figure (b) demonstrates how the forces and moments are calculated in each segment using the conventional \ac{ID} method; variables refer to equation \ref{eq:conventional-id} adapted from \cite{Dumas2004}.}
    \label{fig:ID-forces-and-segments}
\end{figure}
Newton-Euler equations of motion are then used to calculate the net joint forces and moments for each segment as described by figure \ref{fig:cgm-ID-force-prop} and the following equations \cite{Dumas2004}:
\begin{align}
\label{eq:conventional-id}
\begin{split}
    \mathbf{F}_{ip} &= m_i\mathbf{a}_i - m_i\mathbf{g} - \mathbf{F}_{id} \\
    \mathbf{M}^S_{ip} &= \Dot{\mathbf{H}}^S_i - \mathbf{M}^S_{id} - (\mathbf{k}_i^S \times \mathbf{F}^S_{ip}) - (\ell^S_i\times\mathbf{F}^S_{id})
\end{split}
\end{align}
where the subscript $i$ indicates the $i$-th segment, $p$ the proximal end of the segment, and $d$ the distal end. $\mathbf{F}$ is a force vector, $m$ is mass, $\mathbf{a}$ is acceleration, $\mathbf{g}$ is gravitational acceleration, $\mathbf{M}$ is a moment vector, $\Dot{\mathbf{H}}$ is time derivative of the angular momentum, $\mathbf{k}$ and $\ell$ are lever arm vectors from the center of mass to the proximal and distal end, respectively.
The superscript $S$ indicates the segment coordinate system (SCS) as opposed to the inertial coordinate system (ICS).
Therefore, in this conventional method of \ac{ID} the force and moments are calculated in separate coordinate systems and thus requires coordinate transformations.
First for the force to be used in the equation for the moments and then for the moments to be transformed into the ICS.
This complicates the calculations as well as the translation of the force from one segment to the next.

\textcite{Dumas2004} present the \textit{generic} method for \ac{ID} using wrench notation.
With this method the forces and moments can be computed at the same time in the same predefined ICS, thus facilitating the translation from one segment to another.
Figure \ref{fig:generic-ID-forces-and-segments} demonstrate how this method is used to define moments and forces in the femur segment.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.7\textwidth]{img/Generic_ID_original.PNG}
    \caption{The generic method for \ac{ID} computation using wrench notation. Variable names refer to equation \ref{eq:generic-id}. Adapted from \cite{Dumas2004}.}
    \label{fig:generic-ID-forces-and-segments}
\end{figure}
Calculating the force and moment at the proximal end of the $i$-th segment thus goes as follows \cite{Dumas2004}:
\begin{align}
\label{eq:generic-id}
    \biggl\{
            \begin{array}{ll}
              \mathbf{F}_i\\
              \mathbf{M}_i
            \end{array} =&
        \biggl\{
            \begin{array}{cc}
                \mathbf{m}_i\bm{a}_i\\
                \mathbf{I}_i\bm{\alpha}_i + \bm{\omega}_i \times \mathbf{I}_i\bm{\omega}_i + \mathbf{c}_i \times m_i\mathbf{a}_i
            \end{array}
         \nonumber\\
    &- 
    \biggl\{
            \begin{array}{cc}
                m_i\mathbf{g}\\
                \mathbf{c}_i \times m_i\mathbf{g}
            \end{array} -
        \biggl\{
            \begin{array}{cc}
                -\mathbf{F}_{i-1}\\
                -\mathbf{M}_{i-1}-\mathbf{d}_i \times \mathbf{F}_{i-1}
            \end{array}
\end{align}
where $\mathbf{I}$ is the inertia tensor, $\bm{\alpha}$ is the angular acceleration, $\bm{\omega}$ is the angular velocity, $\mathbf{c}$ is the lever arm from proximal end to the center of mass, and $\mathbf{d}$ the lever arm from the proximal end to the distal end.
Notably, the force and moment from previous segment are used in the equation, indicated by the subscript $i-1$.
The initial case is simply the wrench at the center of pressure on the \ac{FP}, defined by the \ac{FP} measured data.

% Extensive research has been done of on inverse dynamics and it is widely used in clinical applications such as, for example, gait analysis in rehabilitation \cite{Erdemir2007,Buchanan2004,Pizzolato2015}.

% OpenSim \cite{Delp2007, Seth2018} is an open-source software offering biomechanical models and simulation tools to, among many other things, model and run inverse dynamic solution on a scaled musculoskeletal model \cite{Buchanan2004, Delp2007, Seth2018, Pizzolato2017}.


% There is a limitation to these optimization methods due to variations in muscle synergies.
% \textcite{Ivanenko2016} define muscle synergies as representing "coordinated activations of groups of muscles, with specific activation balances or temporal profiles, that might reflect basic biomechanical properties of the musculoskeletal apparatus or statistical regularities in the muscle activation patterns involved in performing a specific motor behavior" \parencite[160]{Ivanenko2016}.
% This means that muscles are not necessarily recruited to produce a specific torque at a joint but rather they are recruited as part of a muscle synergy that relates to a specific task, such as taking a step.
% As pointed out by \textcite{Pizzolato2015} the optimization method, including static and dynamic optimization, cannot account for variations in muscle activation patterns (i.e. muscle synergies) between tasks and individuals.
% For example, if the objective function is to minimize the sum of muscle forces that fit a certain joint moment, it does not account for the fact different muscle synergies can produce the same joint moment. 
% Muscle synergies have been shown to be task-specific and vary between individuals and different pathologies \cite{Ivanenko2016, Safavynia2011}.
% To account for this drawback, muscle activation need to be measured and accounted for, for example by using \ac{sEMG} and \ac{EMG}-driven models \cite{Pizzolato2015}.

\subsection{Electromyography and Muscle Activity}
\label{sec:A-EMG}
Muscle forces of the skeletal muscles are the forces produced by the human body to move or stabilize itself. 
The muscle force is generated by muscle contraction which is activated by electrical \ac{AP} travelling through the nerves of the body to and through the muscle fibers. 
A single muscle is comprised of many \acp{MU} which in turn contain many muscle fibers.
Each \ac{MU} is activated by the \ac{AP} from a single motor neuron.
The muscle force produced thus depends, among other factors, on the amount of fibers per \ac{MU} and the number of \acp{MU} activating.
Other factors influencing the muscle force include the fiber properties (e.g. cross-sectional area and specific force), the cooperation of different \acp{MU} within the muscle, \ac{AP} frequency, etc.
Furthermore, if looking at the force exerted by the muscle to the skeleton to produce movement, i.e. the \ac{MTU} force, then the properties of the tendon, such as elasticity, need to be considered as well \cite{Pizzolato2015, Enoka2016, Farina2016}. 

\Ac{EMG} is a way to measure the activity of the muscles.
The \ac{EMG} signal is a biomedical signal measuring the electrical currents that are generated in the muscle as a result from the \ac{AP} \cite{Raez2006}.
The \ac{EMG} signal depends on the number of \acp{MU} activated and the \ac{AP} frequency and has been found to correlate with the muscle force.
However, the relation between the two varies from muscle to muscle and furthermore, both relate non-linearly to the neural drive from the motor neuron.
Consequently, \ac{EMG} does not directly measure muscle forces but is rather an indication of how activated the \acp{MU} are \cite{Enoka2016, Farina2016}.

There are two common methods of measuring \ac{EMG}, one being the invasive method where a needle electrode is inserted percutaneously to the target muscle, and the second being the surface \ac{EMG} method where electrodes are placed on the skin close to the target muscle. 
Although the invasive method can give a more accurate signal, the \ac{sEMG} method is more widely used due to the fact that it is non-invasive and easier to implement. 
The continued discussion here about \ac{EMG}s will be focused on the \ac{sEMG} method.
When using the \ac{sEMG} method the source of the signal and the recording electrodes are separated by biological tissues (e.g. skin, fat, blood vessels).
The signal can still be detected as the \ac{AP} in the muscle fibers generates an electric field in the surrounding tissue with conducting properties.
However, these tissues act as spatial and temporal low-pass filters with resulting deforming effect on the signal.
A common method to partially compensate for the spatial low-pass filtering is to use a pair of electrodes positioned few cm apart.
This method also allows removing the common-mode component (e.g. $50Hz$ from power line interference) \cite{Farina2016}.

Some other artifacts of the \ac{sEMG} signal include, for example, end-of-fiber effect, electrode-skin impedance, and crosstalk \cite{Farina2016}.
Due to all these implications and artifacts the signal recorded by the electrodes depends on a number of anatomical, physical, and detection system parameters, as discussed by \textcite[p. 41]{Farina2016}. 
As a result, the \ac{sEMG} signal can vary highly between individuals as well as between days and measurements of the same individual.

Guidelines have been made by \ac{SENIAM} in effort to make \ac{sEMG} procedures more standardized and comparable and to increase reproducibility of the experiment. 
The \ac{SENIAM} project is a European concerted action towards development of recommendations on sensors, sensor placement, signal processing, and modelling for \ac{sEMG} \cite{Hermens1999, Hermens2000}.
One setback of \ac{sEMG} is that it can only measure muscles near the surface.
If the muscle is located behind other muscles, or if there is too much tissue between the source of the signal and the electrodes, or the position of the electrodes are closer to another muscle, then the integrity and selectivity of the signal is compromised \cite{Farina2016, Hermens2000}.
The \ac{SENIAM} project provides \ac{sEMG} electrode placement recommendations for 14 muscles on lower extremities, including the hip \cite{Hermens1999}.

The amplitude of \ac{EMG} signal is in the range of $\pm 5$ or $0-10 mV$ but it is random in nature \cite{Raez2006}.
The firing rate of the \acp{MU} is in the range of $0-20Hz$.

\subsection{Joint Moments from \ac{EMG} and Muscle Force}
\label{sec:A-EMGBasedModels}
As previously mentioned, \ac{EMG} measure muscle activation and not muscle forces but there is a correlation between the two.
\ac{EMG}-based models are models developed towards estimating muscle forces and/or joint torques based on \ac{EMG} data \cite{Erdemir2007, Pizzolato2015}.
These models are often based on a modified Hill-type muscle model. 
It describes how the muscle's normalized isometric force  ($F^{norm}_t$) depends on the optimal fibre length ($L^O_m$), tendon slack length ($L^S_T$), and the muscle pennation angle ($\phi (t)$) \cite{Winby2008, Lloyd2003}.
The equation for this type of model, as presented by \textcite{Lloyd2003}, and represented by calculating the \ac{MTU} force ($F^{mt}(t)$) is given by
\begin{align}
\label{eq:hill-equation}
\begin{split}
    F^{mt}(t) &= F^{max} \left[ f(l)f(v)a(t) + f_p(l) \right] \cos{\left(\phi (t)\right)} \\
    \phi (t) &= \sin^{-1}\left( \frac{L^O_m\sin{\phi_0}}{L^m(t)}\right)
\end{split}
\end{align}
where $F^{max}$ is the maximum isometric muscle force; $f(v)$ and $f(l)$ the normalized fiber forces dependent on velocity and length respectively; $a(t)$ the time varying muscle activation; $f_p(l)$ the parallel passive elastic force–length; $L^m(t)$ the muscle fiber length at time $t$; and $\phi_0$ the pennation angle at $L^O_m$ \cite{Buchanan2004, Winby2008, Lloyd2003}.
% The model geometry of a single \ac{MTU} is represented in figure \ref{fig:MTU-unit}.
% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.75\textwidth]{img/MTU-unit}
%     \caption{Representation of a \ac{MTU} showing the muscle force $F^m$, tendon force $F^t$, muscle and tendon lengths $L^m$ and $L^t$ respectively, and the pennation angle $\phi$. The figure is adapted and modified from \cite[Fig. 5]{Buchanan2004}}
%     \label{fig:MTU-unit}
% \end{figure}

The way these models are based on \ac{EMG} is that the muscle activation, $a(t)$ in equation \ref{eq:hill-equation}, can be measured with \ac{EMG}.
Other parameters, such as $L^O_m$ and $L^S_T$, are difficult to measure \cite{Winby2008}.
\textcite{Lloyd2003} handle this problem by giving these parameters initial estimations based on previous studies and measurements. 
The values are then allowed to be adjusted, within a certain limit, to best fit values obtained using an \ac{ID} approach.
Thus, the model can be calibrated using the \ac{ID} and then used independently using only the \ac{EMG} signal and the measured parameters from equation \ref{eq:hill-equation}, as long as they do not change with time.
However, if the parameters do change, for example if the individual might become stronger or weaker, they need to be measured again and the model re-calibrated.

% Thus, in a way, this \ac{EMG}-based model is still uses optimization but it should better reflect on the muscle activation pattern than the previously discussed static and dynamic optimization \cite{Pizzolato2015, Lloyd2003}

\section{Exoskeletons as Assistive Devices}
\label{sec:A-Exoskeletons}
As previously mentioned, an exoskeleton can be defined as mobile, computer controlled, electromechanical structure which can be worn by a human to provide power amplification, support and/or assistance in human motion \cite{Anam2012, Gorgey2018}.
Figure \ref{fig:exoskeleton} shows an example of exoskeletons currently on the market.
The focus here will be on exoskeletons as assistive devices for those with physical impairment, i.e. for rehabilitation and/or assisting healthy human motion. 
This excludes exoskeletons as power amplification for professional or military purposes.
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{img/exoskeleton_fig}
    \caption{Two different designs of an exoskeleton. The one on the left is the Hybrid Assistive Limb exoskeleton developed by Cyberdyne for the purpose of aiding individuals with disabilities. The one on the right is the Ekso exoskeleton which is mostly used for rehabilitation purposes. The figure is adapted from \cite[Fig. 3]{Young2017}}
    \label{fig:exoskeleton}
\end{figure}
To be able to provide assistance to motion the exoskeleton needs a human-exoskeleton interaction together with a control system.
The control system is how the human motion is translated into mechanical activation, and vice versa. 
\textcite{Anam2012} list four different categorizations of control systems in exoskeletons, namely \textit{Model-based}, \textit{Hierarchy based}, \textit{Physical parameters based}, and \textit{Usage based}. 
For the purpose of this review the focus is set on the first categorization, i.e. \textit{Model-based} control systems.
The article states that the control strategy of an exoskeleton can be divided into two types depending on the model used, namely the \textit{dynamic model} and the \textit{muscle model} based control. 

\textcite{Anam2012} divide the \textit{dynamic model} into three different categories, each with its strengths and weaknesses.
These models use the system's physical characteristics and motion data to estimate moments and/or forces required from the exoskeleton. 
For example, one of the categories is the artificial intelligence method where one study has used the joint angle, angle velocity, and angle acceleration as input to the model and the joint torque as output, behaving like an inverse dynamics model.

The \textit{muscle model} uses muscle neural activity and/or joint kinematics to predict muscle forces and resulting joint moments. 
These models can be split into two categories: parametric and non-parametric muscle model. 
The difference between them is that in addition to \ac{EMG} data the parametric model needs anthropometric data with information of muscle and joint dynamic \cite{Anam2012}.
This is much like the \ac{EMG}-driven models discussed in the previous chapter \cite{Pizzolato2015}.
The \textit{muscle model} has been researched as a way to provide real-time prediction of muscle forces and joint torques \cite{Pizzolato2015, Anam2012, durandau}. 
Furthermore, as mentioned by \textcite{Anam2012}, much effort has been made towards predicting the user's intentions beforehand by using \ac{EMG} data.
The Hill-type muscle model is possibly the most researched parametric muscle model and some modifications of it have been made throughout the years to make it more accurate \cite{Pizzolato2015, Lloyd2003, Anam2012, Lee14-1}.
For the non-parametric muscle model an artificial neural network could be used \cite{Lee14-1, Kiguchi2012}.  

\section{Artificial neural networks in biomechanics}
The methods to predict joint torque discussed previously all use calculations based on anthropometry and dynamic models of the human body. 
The measured parameters, such as \ac{EMG}, motion, and reaction force data, are used as input into equations based on specific dynamic models of the human body, to estimate the joint torque that best fits the input.
\Ac{ANN} on the contrary treats the model part as sort of a \textit{black box} and does not depend on these dynamic models. 
Rather, it simulates the model with a self-organized calculations based on statistical methods.
This means that the \ac{ANN} goes from an input to desired output without direct relations to dynamic models of the human body.
This is important when looking at going from an \ac{EMG} signal to joint torque prediction since the projection of \ac{EMG} to muscle force and joint torque is not easily established through dynamic models.
Motion data and reaction forces are needed to get joint torque from dynamic models, and this is typically not possible to measure in an exoskeleton.

\subsection{Machine Learning}
Machine learning refers to a computer algorithm with the ability to learn from data \cite{Goodfellow2016}. 
\textcite{Mitchell1997} gives the following definition of that learning: ``A computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$, if its performance at tasks in $T$, as measured by $P$, improves with experience $E$'' \parencite[2]{Mitchell1997}.

Machine learning algorithms contain subcategories of different algorithms within which \ac{ANN} is only one of many.
In addition, \ac{ANN} contains more subcategories depending on number of design factors such as topology.

Most machine learning algorithms, including \acp{ANN}, can be categorized into two groups depending on the manner of learning.
These categories are \textit{supervised learning} and \textit{unsupervised learning} \cite{Goodfellow2016}.
This categorization is visually presented in figure \ref{fig:types-of-learning}.
The focus of this chapter will be on \acp{ANN} using \textit{supervised learning} or more specifically \textit{corrective learning}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{img/types-of-learning-diagram.pdf}
    \caption{The tree shows how machine learning algorithms can be categorized by different types of learning. The diagram is based on \cite[Fig. 4.3]{Rojas1996a}}
    \label{fig:types-of-learning}
\end{figure}

\textit{Supervised learning} differs from \textit{unsupervised learning} in that the training data (i.e. the aforementioned ``experience'') is paired with associated \textit{label} or \textit{target}.
The ``performance measure'' is then how accurately the algorithm can map a data set (or \textit{features}), $\mathbf{x}$, to the associated target, $y$ \cite{Goodfellow2016}.
How the accuracy is measured and how that measure is used to ``teach'' the algorithm varies between the different designs of algorithms.
To summarize, supervised learning algorithms typically aim at estimating the probability distribution $p(y | \mathbf{x})$ \cite{Goodfellow2016}.

The ``classes of tasks'', mentioned in the definition referenced above, contains many different types \cite{Goodfellow2016}.
However, the focus here will be on two, arguably most researched tasks within \textit{supervised learning}, namely \textit{Classification} and \textit{Regression}.

All these concepts of machine learning apply to the subcategory of \acp{ANN} as well, which will be discussed in the next section.

%Curse of dimensionality: "one challenge posed by the curse of dimensionality is a statistical challenge which arises because the number of possible configurations of $x$ is much larger than the number of training examples" \parencite[153]{Goodfellow2016}.

%Capacity: Representational capacity is what "specifies which family of functions the learning algorithm can choose from". Effective capacity refers to the fact that the "best" function within the family is rarely found and thus the actual capacity may be less than the representational capacity \parencite[111]{Goodfellow2016}.

%"The answer to both of these questions—whether it is possible to represent a complicated function efficiently, and whether it is possible for the estimated function to generalize well to new inputs—is yes. The key insight is that a very large number of regions, such as O(2k ), can be defined withO(k) examples, so long as we introduce some dependencies between the regions through additional assumptions about the underlying data-generating distribution. In this way, we can actually generalize nonlocally (Bengio and Monperrus, 2005; Bengio et al., 2006c). Many different deep learning algorithms provide implicit or explicit assumptions that are reasonable for a broad range of AI tasks in order to capture these advantages." \parencite[156]{Goodfellow2016}
One of the most important challenge and goal of machine learning is generalization, i.e. that the trained algorithm works equally well on data it has not been presented with before. 
This highly relates to the concepts of overfitting and underfitting, as defined by \textcite{Goodfellow2016} and represented in figure \ref{fig:over-vs-under}: ``Underﬁtting occurs when the model is not able to obtain a suﬃciently low error value on the training set. Overﬁtting occurs when the gap between the training error and test error is too large'' \parencite[109]{Goodfellow2016}.
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{img/overfitting-vs-underfitting}
    \caption{Algorithm results for machine learning regression of a quadratic function. The blue dots are training samples, the red dot is a testing sample, and the blue line is the algorithms result. On the left there is a high error on the training set, and even though the test set is accurately predicted it is not reliable as there is underfitting. On the right there is clearly a huge error on the test set even though the training set is accurately predicted by the algorithm. Figure is adapted and modified from \cite[Fig. 5.2]{Goodfellow2016}}
    \label{fig:over-vs-under}
\end{figure}

\subsection{Neural Networks}
\label{sec:A-NeuralNetworks}
Like the name suggests \acp{ANN} consist of multiple ``artificial neurons'', often called nodes, that are interconnected by pathways for communication.
\textit{Topology} refers to how these nodes are placed (e.g. into layers), how many there are, and how they are connected.
Figure \ref{fig:generic-ann} shows an example of a generic multilayer feed-forward \ac{ANN}, also known as \ac{DNN} or \ac{MLP}.
It is feed-forward since it does not contain any feed-back loops, as opposed to \acp{RNN} \cite{Goodfellow2016, Haykin2009}. 
Furthermore, it is multilayer as it contains hidden layers, additionally to the input and output layer.
\begin{figure}[ht!]
    \centering
    \includegraphics{img/generic-ann-diagram}
    \caption{Generic feed-forward neural network: Layers are (from left to right): an input layer (filled black nodes), two hidden layers, and an output layer. The arrows and the turquoise filled nodes together form a function $f$ which maps the input to the output: $f(\mathbf{x})=\mathbf{y} $.}
    \label{fig:generic-ann}
\end{figure}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.6\textwidth]{img/node-diagram}
    \caption{Single node diagram: Shows the inputs $\mathbf{x}$ into a single node of a \ac{NN} and the nodes functionality and process to get an output $\mathbf{y}$. The colored items can all be considered to be part of the node as represented in figure \ref{fig:generic-ann}. The circle denotes the summation of inputs and the square denotes the activation of the node. The figure is based on \cite[Fig. 5]{Haykin2009}.}
    \label{fig:node-diagram}
\end{figure}
Figure \ref{fig:node-diagram} shows a better visualization of what happens at each node of the network.
Each arrow of the feed-forward network is associated with a weight, often denoted with $w$, and each node has a summation characteristic and an \textit{activation function} which determines if (or how much) the node activates.
The node diagram can be represented mathematically with the following two equations:
\begin{subequations}
\label{eq:ann-node}
\begin{align}
    v_k &= \sum_{j=1}^m w_{kj}x_j + b_k \\
    y_k &= \phi (v_k)
\end{align}
\end{subequations}

In this thesis, two types of activation functions are used.
These are the \ac{ReLU} from equation \ref{eq:relu-function} and the hard-sigmoid from equation \ref{eq:hard-sigmoid-function} \cite{Goodfellow2016, Nwankpa2018}:
\begin{align}
\label{eq:relu-function}
    \phi (z) = \max\left\{0,z\right\}
\end{align}
\begin{align}
\label{eq:hard-sigmoid-function}
    \phi (z) = \max\left\{0,\min\left\{1,\frac{(z+1)}{2}\right\}\right\}-\left(1.6\right)
\end{align}
The \ac{ReLU} activation function is computationally light and has been shown to perform better than many other functions.
This has resulted in it being the most widely used activation function since it was proposed in 2010 \cite{Nwankpa2018}.
Unlike the hard-sigmoid, and many other activation functions, the \ac{ReLU} does not saturate.
In the gates of the \ac{LSTM}-cell, presented in next section, it is preferred to have saturation.
That is where the hard-sigmoid function is used instead of the \ac{ReLU}.

Relating figure \ref{fig:generic-ann} to previously defined learning, the \textit{task} might be classification where each $y$ represents a class.
The \textit{experience} is the $n$ dimensional training data set which is fed into the input layer of the network, as the vector $\mathbf{x}$.
The information then propagates through the network, layer by layer, to the output layer. 
This is a process called \textit{forward-propagation} \cite{Goodfellow2016}.
The \textit{performance measure} is then how close the output $\mathbf{y}$ is to the target $t$.
If the output is not ``close enough'' to the target then the mapping function $f$, represented by the arrows and nodes, needs to be updated.
As previously mentioned and shown in figure \ref{fig:node-diagram}, each arrow has an associated weight and these weights are what can be updated to affect $f$.
The update is then typically to minimize a certain cost-function representing the error between the output and the target (e.g. $(y-t)^2$).
This is done through a process called \textit{back-propagation} or \textit{backprop} for short.

Backprop is about computing the gradient of $f$ from node to node using the chain rule for derivatives. 
The weights are then typically updated to minimize the cost function using gradient descent.
To enable this method the activation function has to be differentiable, i.e. it can not be the step function for example.
Popular activation functions include for example the sigmoid or the hyperbolic tangent function and the ReLu or softplus function \cite{Goodfellow2016, Haykin2009, Rojas1996}.

This brief introduction of neural networks and how they learn has been focused around the feed-forward network.
They are sort of the basis of deep learning models and much of the same or similar principles apply to other deep neural networks \cite{Goodfellow2016}.

\subsection{Recurrent Neural Networks}
\label{sec:A-rnn}
\Acp{RNN} are \acp{DNN} specifically designed to work on sequences of data.
It introduces the recurrence wherein the hidden state and/or output from one time step in a sequence is fed into the next time step.
This introduces a time dependency in the network which can more accurately portray the dependency between time steps in a sequence.
Figure \ref{fig:generic-rnn} illustrates an representation example for such a network.
\begin{figure}[ht]
    \centering
    \includegraphics{img/generic-rnn-diagram}
    \caption{Generic \ac{RNN}: To the left is a general representation of a \ac{RNN} and to the right is the unfold representation of that same \ac{RNN}. $\mathbf{x}^{(t)}$ represents all the features at time step $t$; $U$, $V$, and $W$ are the weight matrices;}
    \label{fig:generic-rnn}
\end{figure}

The time steps do not necessarily represent actual steps through time.
They can simply refer to steps in an atemporal sequence.
Although, with this thesis in mind one could consider them as temporal sequence steps.
More specifically, each time step is an \ac{EMG} sample in a temporal sequence of \ac{EMG} samples.

There is a known issue with the so called vanishing gradient (or exploding gradient) in deep learning networks, including \acp{RNN}.
Simply put, the issue is introduced from the repeated multiplication of the weight matrices in the backpropagation algorithm.
When the weight is small and multiplied by itself many times, like in an long-term time dependency in a \ac{RNN}, the product becomes very small.
The backpropagation is used for computing the gradient which in turn is used to update the weights to minimize the cost function.
As a result, the issue of the vanishing gradient results in the weights not being updated, and thus the algorithm stops learning.
One solution to the problem in long-term time dependency networks is the \ac{LSTM}.

A \ac{LSTM} based \ac{RNN} contains the \ac{LSTM}-cell which consists of a system of gating units.
The gating units control the flow of the information through the network.
They have the power to keep, partially keep, or getting rid of the information.
The cell also holds a cell-state which is recurrent and is updated by the gates.
Figure \ref{fig:lstm-cell} demonstrates the flow of information through the \ac{LSTM} and equations \ref{eq:lstm_sigmoid_generic}--\ref{eq:last_lstm_step} write out the process \cite{Goodfellow2016}.
\begin{figure}[ht!]
    \centering
    \includegraphics{img/LSTM-cell.pdf}
    \caption{The \ac{LSTM} cell. Variables and operations reference equations \ref{eq:lstm-ff}. The boxes indicate a \ac{ANN} layer and the circles indicate matrix math operations. The dashed arrow indicates the possibility of getting the output from this timesteps status. The diagram is a highly modified version of an image from http://colah.github.io/posts/2015-08-Understanding-LSTMs/}
    \label{fig:lstm-cell}
\end{figure}
The cell contains four separate sigmoid units that work similar to the regular \ac{ANN} node from figure \ref{fig:node-diagram}.
Equations \ref{eq:ann-node} become \cite{Goodfellow2016}:
\begin{equation}
\label{eq:lstm_sigmoid_generic}
    \sigma^{\alpha}\left(b^{\alpha} + \sum_i{U_i^{\alpha} x_i^{(t)}} + \sum_i{W_i^{\alpha} h_i^{(t-1)}} \right)
\end{equation}
where $b$, $U$, and $W$ are the biases, input weights, and recurrent weights, respectively.
$x^{(t)}$ is the input at current step and $h^{(t-1)}$ the hidden state from the previous step.
$\alpha$ is an indicator of the separate units and their parameters.
The flow of data through the cell is then as shown in equations \ref{eq:lstm-ff} \cite{Goodfellow2016}:
\begin{subequations}
\label{eq:lstm-ff}
\begin{align}
    f^{(t)} &= \sigma^f\\
    g^{(t)} &= \sigma^g\\
    q^{(t)} &= \sigma^q\\
    s^{(t)} &= f^{(t)}s^{(t-1)} + g^{(t)}\sigma^s\\
    h^{(t)} &= \tanh\left(s^{(t)}\right)q^{(t)} \label{eq:last_lstm_step}
\end{align}
\end{subequations}
As seen from figure \ref{fig:lstm-cell}, the input to the cell is the hidden state $h^{(t)}$, and the cell state from the previous timestep $s^{(t)}$, as well as the input sample from the current timestep $x^{(t)}$.
The $\times$ operations from the figure are the gates where $f^{(t)}$ is the forget gate, $g^{(t)}$ is the input gate, and $q^{(t)}$ the output gate.
Essentially, what happens every time step is that the state of the cell is first updated with the current input before it is used to control the output through the output gate.
The recurrence of $s^{(t)}$ introduces a path through time where the gradient can flow without the problem of vanishing (or exploding).



%"It is best to think of feedforward networks as function approximation machines that are designed to achieve statistical generalization" \parencite[165]{Goodfellow2016}.

\subsection{Neural Networks for Biomechanics}
The use of neural networks to predict joint dynamics is nothing new.
\textcite{Sepulveda1993} constructed a \ac{MLP} with a single hidden layer to predict joint angles and joint moments based on EMG signals, more than 20 years ago. 
The training of this relatively small network took a very long time.
Furthermore, the results of the trained algorithm indicate overfitting.
Since then, extended processing power of modern computers has enabled use of more complicated and deeper networks.
Furthermore, extended research into machine learning in recent years has created a lot of recommendations and best practices to improve the algorithm's design and performance.

With the current immense popularity with neural networks, many researches have provided alternative algorithms to solve the task of joint torque prediction.
\textcite{Ardestani2014} provide a multi-dimensional wavelet neural network to estimate lower extremity joint moments. 
The input to the network is \ac{EMG} and \ac{GRF} data collected during gait trials of four patients with knee prosthesis.
Notably, the dataset used in their research could not be considered very large in relation to machine learning (i.e. 120 gait cycles in total).
Including the \ac{GRF} as input decreases the flexibility of using the model in real time since \ac{GRF} measurements are typically more difficult to obtain than \ac{EMG}.
The prediction error of \ac{KJM} seems to be up to around 10\% Normalized-RMSE, depending on walking pattern.
\textcite{Lee14-1} use a NNARX (Neural Network, AutoRegressive, eXternal Input) model to estimate knee joint moment in sit-to-stand movement. 
The input was \ac{EMG}, joint angle, and joint velocity as well as previously predicted joint moment. 
\textcite{Kiguchi2012} present a neuro-fuzzy system to estimate joint torques in the upper-limb to use with a power-assist exoskeleton. 
The input to the neuro-fuzzy system is the joint angles and the output are weights to be multiplied by measured \ac{EMG} RMS values.
\textcite{Cui2016} use a NARX-type dynamic \ac{RNN} to estimate lower extremity joint angles during cycling. 
The input is \ac{EMG} signal and feedback from previous prediction.

The challenges related to using \ac{EMG} signal is its redundancy, nonlinear characteristics, and variability between tasks, subjects, conditions (e.g. pathologies, muscle fatigue), etc.
There are many muscles that contribute to the joint torque and with the nonlinear characteristics a higher dimensional data is needed to be able to map the relationship.
However, with higher dimension and the redundancy of the \ac{EMG} signal, there is a risk of overfitting.
Furthermore, due to the variability it is difficult to get a solution that is generalizable.
When working with \ac{EMG} data from many muscles it is useful to preprocess the data with dimensionality reduction and feature extraction and selection. This can contribute to learning efficiency and improve generalization \cite{Chen2018, Marsland2014}.

\section{Platforms}
\label{sec:A-Platforms}
\subsection{Vicon Nexus and Plug-in Gait}
\label{sec:A-Vicon-and-PiG}
The Vicon Nexus motion capture system, equipped with motion capture cameras, is capable of capturing motion of a subject wearing markers, doing all sorts of exercises \cite{vicon-user-guide}.
The motion data can be synchronized with analog data captures, such as \ac{FP} and \ac{EMG} data, and analyzed using the Vicon Nexus software.
The software offers the option of running biomechanical models on the data captured. 
That includes scaling the labelling skeleton based on anthropometric data and performing inverse kinematics.

\Ac{PiG} is a biomechanical model offering full body kinematic and kinetic modeling. 
It is Vicon's implementation of the \ac{CGM} and is based on the Newington-Helen Hayes gait model \cite{vicon-user-guide, viconpig}. 
The model  comprises 7 segments on the lower body, with an orthogonal coordinate system associated with each segment \cite{Baker2017}.
The kinematic and kinetic outputs are based on the orientation of the distal segment relative to the proximal segment \cite{Leboeuf2019, Baker2017, cgm-outputs}. 
Figure \ref{fig:knee-joint-coordinates} illustrates the coordinate system setup for the knee joint.
Using the right-hand rule, one can determine that knee flexion/extension is indicated by positive/negative rotation around the y-axis.
\begin{figure}[!htb]
    \centering
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{img/LeftFootFemur_PiG_wCoord.png}
        \caption{Adapted from \cite{Baker2017}}
        \label{fig:cgm23-femur-jc}
    \end{subfigure}
     ~
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/KneeJointAngles_wCoord_twisted.png}
        \caption{Adapted from \cite{cgm-outputs}}
        \label{fig:cgm23-knee-coordinate-system}
    \end{subfigure}
     ~
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{img/experiment_capture2.pdf}
        \caption{Screenshot from Vicon Nexus during trial.}
        \label{fig:A-cgm23-markerset-experiment-capture}
    \end{subfigure}
    \caption{\Ac{KJC} placement and coordinate system setup. The red, green, and blue (RGB) color code indicates x-, y-, and z-axis respectively. (a) The femur of the left leg. z-axis extends from the \ac{KJC} through the \ac{HJC} and the y-axis from the \ac{KJC} through the lateral epicondyle marker in the coronal plane of the femur. (b) The grey circle shows the sagittal plane of the femur. The flexion/extension angle is defined by the rotation of the tibia around the y-axis in the sagittal plane, indicated by the green angle. (c) Model built using CGM2.3 setup. The coordinate system is shown at the \ac{KJC}, notably oriented the same way for the left and the right leg.}
    \label{fig:knee-joint-coordinates}
\end{figure}
\Ac{PiG} is included in the Vicon Nexus software and includes a markerset protocol, labelling skeleton, and pipelines for static and dynamic calibrations. 

\subsection{pyCGM2}
\label{sec:A-pyCGM2}
The pyCGM2 package is a python package which implements, among other things, kinematic and kinetic computations based on motion data contained in c3d files \cite{Leboeuf2019}.
The package is an upgrade to the \ac{PiG} model intended to improve it by fixing known issues \cite{Leboeuf2019}.
The first version, CGM1.0 was intended to replicate the \ac{PiG} model outputs exactly and following versions to build upon it.
From CGM1.0 to CGM2.1 the medial knee marker for knee joint center calibration was added, demonstrated in figure \ref{fig:cgm23-markerset-sota}.
Furthermore, known issues and inconsistencies within kinematic calculations and hip joint center calibration calculations were fixed \cite{Leboeuf2019}.
% CGM1.1 fixes the definition of pelvis rotation to be the rotation of the pelvis with respect to its own axis rather than the axis of the laboratory.
% It also fixes
CGM2.2 introduces the use of \ac{IK} and with it some improvements that can be read about on the CGM2 website \cite{cgm22}. 
CGM2.3 introduces additional markers to minimize a soft tissue artifact accompanying the \ac{IK} method when using the thigh and calf wands \cite{cgm23}.
\begin{figure}[!hbt]
    \centering
    \includegraphics[width=0.6\textwidth]{img/CGM23_markerset_highlight.png}
    \caption{The markerset as defined for version CGM2.3. The changes from the original CGM1.0 markerset are highlighted with orange circles/arrows. Adapted from pyCGM2 official website \cite{cgm23}}
    \label{fig:cgm23-markerset-sota}
\end{figure}

\subsection{TensorFlow and Keras}
\label{sec:A-Tensorflow-and-Keras}
TensorFlow and Keras are \acp{API} that can be used to design, run, and evaluate machine learning algorithms \cite{tensorflow2015-whitepaper, chollet2015keras}.
Both projects offer open-source python packages.
The algorithm within TensorFlow consist of a directed \textit{graph}, composed of a set of connected \textit{nodes}, containing states and computations, much like previously explained in section \ref{sec:A-NeuralNetworks}.
TensorFlow offers high flexibility towards how the graphs are constructed and configured \cite{tensorflow2015-whitepaper}.
Keras offers a high-level \ac{ANN} \ac{API} which can run on top of TensorFlow \cite{chollet2015keras}.
The API facilitates building a conventional \ac{ANN}, layer-wise, in a TensorFlow graph.
An example of a layer in Keras is the \textit{Dense} function which constructs the regular, densely connected layer as described in figure \ref{fig:generic-ann}.
The function takes as an input, the number of nodes (or units) and the activation functions, weight, and bias initialization applied to each node as described in figure \ref{fig:node-diagram}.

\end{document}