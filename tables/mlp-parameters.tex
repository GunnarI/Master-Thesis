\begin{table}[!htb]
    \centering
    \caption{\ac{MLP} parameter values used in the Keras API function \cite{chollet2015keras}.}
    \begin{tabular}{>{\raggedright}p{0.15\textwidth} | c | p{0.5\textwidth}}
        \textbf{Parameter}              & \textbf{Value}            & \textbf{Function} \\ \hline
        Hidden layers                   & $2$                       & The number of densely connected layers of \ac{NN} units (see figure \ref{fig:node-diagram}). \\ \hline
        Units                           & $(64, 64)$     & The number of hidden units in each layer. \\ \hline
        Activation function             & (ReLU, ReLU)              & The node's activation function for each layer.\\ \hline
        Dropout rate                    & $(0.3, 0.3)$   & The dropout rate after each layer. \\ \hline
    \end{tabular}
    \label{tab:mlp-parameters}
\end{table}